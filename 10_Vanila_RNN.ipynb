{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_Vanila_RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbkYd8LH59e7HP0nyw23pY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaheeKo/Deep-learning-study/blob/main/10_Vanila_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIaeo-Y9vLg8"
      },
      "source": [
        "**1. Numpy로 구현해보기**\n",
        "\n",
        "< 방법 >\n",
        "\n",
        "hidden_state_t 초기 은닉 상태를 0벡터로 초기화\n",
        "\n",
        "각 시점마다 input_t을 받아서\n",
        "\n",
        "output_t: 입력과 은닉상태를 가지고 연산(tanh)\n",
        "\n",
        "계산결과 -> 출력이면서, 다시 현재 시점의 은닉상태가 됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJRtqpWbOOJ_"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 10 # 시점의 수, NLP에서 보통 문장의 길이\n",
        "input_size = 4 # 입력의 차원, NLP에서 보통 단어 벡터의 차원 \n",
        "hidden_size = 8 # 은닉 상태의 크기, 메모리 셀의 용량\n",
        "\n",
        "inputs = np.random.random((timesteps, input_size)) # 입력에 해당, 2D 텐서\n",
        "hidden_state_t = np.zeros((hidden_size,)) # 초기 은닉 상태 초기화\n",
        "\n",
        "Wx = np.random.random((hidden_size, input_size)) # 입력에 대한 가중치\n",
        "Wh = np.random.random((hidden_size, hidden_size)) # 은닉상태에 대한 가중치\n",
        "b = np.random.random((hidden_size,)) # 편향\n",
        " # => 출력은 (hidden_size,)로 나옴\n",
        "\n",
        "total_hidden_state = []\n",
        "\n",
        "for input_t in inputs:\n",
        "  output_t = np.tanh(np.dot(Wx, input_t) + np.dot(Wh, hidden_state) + b)\n",
        "  total_hidden_state.append(output_t)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}